{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Veriyi eğitim ve test setlerine ayırıyoruz. Modelin genelleştirme yeteneğini test etmek için önemlidir.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Etiketleri sayısal değerlere çeviriyoruz. Kategorik sınıfları modelin anlayacağı hale getiriyoruz.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Resimlerin okunması, resim ve etiket dizilerinin oluşturulma  aşaması\n",
    "inputBasePath = r\"C:\\Users\\İbrahim Demir\\Desktop\\Yeni klasör\\images\"\n",
    "outputBasePath = r\"C:\\Users\\İbrahim Demir\\Desktop\\Yeni klasör\\imagearrays\"\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "classes = ['cat', 'dog']\n",
    "# Çalışma dizinini değiştiriyoruz, böylece veri setine erişim kolay olur.\n",
    "os.chdir(inputBasePath)\n",
    "\n",
    "X = []  # Resimleri tutmak için\n",
    "Y = []  # Etiketleri tutmak için\n",
    "\n",
    "for class1 in classes:\n",
    "# Çalışma dizinini değiştiriyoruz, böylece veri setine erişim kolay olur.\n",
    "    os.chdir(class1)\n",
    "    print('=> ' + class1)\n",
    "    for files in os.listdir('./'):\n",
    "# Görüntüyü okuyoruz ve yeniden boyutlandırıyoruz, çünkü model belirli bir giriş boyutu bekler.\n",
    "        img = cv2.imread(files)\n",
    "        img = cv2.resize(img, (image_width, image_height))\n",
    "        X.append(img)\n",
    "        Y.append(class1)\n",
    "# Çalışma dizinini değiştiriyoruz, böylece veri setine erişim kolay olur.\n",
    "    os.chdir('..')\n",
    "\n",
    "print(\"X : \", len(X))\n",
    "print(\"Y : \", len(Y))\n",
    "\n",
    "X = np.array(X).reshape(-1, image_width, image_height, 3)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(\"X : \", X.shape)\n",
    "print(\"Y : \", Y.shape)\n",
    "\n",
    "# Çalışma dizinini değiştiriyoruz, böylece veri setine erişim kolay olur.\n",
    "os.chdir(outputBasePath)\n",
    "np.save(str(image_width) + 'x' + str(image_height) + '_images', X)\n",
    "np.save(str(image_width) + 'x' + str(image_height) + '_labels', Y)\n",
    "\n",
    "print(\"[ INFO - STAGE1 ]  NUMPY ARRAY CREATION COMPLETED \\n \")\n",
    "\n",
    "# Sınıflandırma işlemleri\n",
    "data = np.load(r\"C:\\Users\\İbrahim Demir\\Desktop\\Yeni klasör\\imagearrays\\\\224x224_images.npy\")\n",
    "labels = np.load(r\"C:\\Users\\İbrahim Demir\\Desktop\\Yeni klasör\\imagearrays\\\\224x224_labels.npy\")\n",
    "\n",
    "# Label Encoding\n",
    "# Etiketleri sayısal değerlere çeviriyoruz. Kategorik sınıfları modelin anlayacağı hale getiriyoruz.\n",
    "labelEn = LabelEncoder()\n",
    "labels = labelEn.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Train - Test Split\n",
    "# Veriyi eğitim ve test setlerine ayırıyoruz. Modelin genelleştirme yeteneğini test etmek için önemlidir.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, shuffle=True)\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "x_train shape: {}\n",
    "x_test shape: {}\n",
    "y_train shape: {}\n",
    "y_test shape: {}\n",
    "\"\"\".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "# Normalizasyon\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_test_mean) / x_test_std\n",
    "\n",
    "# Train - Validation Split\n",
    "# Veriyi eğitim ve test setlerine ayırıyoruz. Modelin genelleştirme yeteneğini test etmek için önemlidir.\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.10, shuffle=True, random_state=42)\n",
    "\n",
    "# Model tanımlama\n",
    "def model1(input_shape=(image_width, image_height, 3), num_classes=2):\n",
    "    model = Sequential()\n",
    "    chanDim = -1\n",
    "\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Havuzlama katmanı ekleniyor. Özellik haritasının boyutunu küçültüp hesaplama maliyetini azaltır.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Havuzlama katmanı ekleniyor. Özellik haritasının boyutunu küçültüp hesaplama maliyetini azaltır.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Havuzlama katmanı ekleniyor. Özellik haritasının boyutunu küçültüp hesaplama maliyetini azaltır.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Evrişim katmanı ekleniyor. Görüntüden anlamlı özellikleri çıkarmak için kullanılır.\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "# Havuzlama katmanı ekleniyor. Özellik haritasının boyutunu küçültüp hesaplama maliyetini azaltır.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "# Tam bağlı katman ekleniyor. Özellikleri kullanarak sınıflandırma yapacak nöronlar.\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "# Tam bağlı katman ekleniyor. Özellikleri kullanarak sınıflandırma yapacak nöronlar.\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = model1()\n",
    "model.summary()\n",
    "\n",
    "# Optimizer tanımlama\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# LR annealer tanımlama\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Modeli derle\n",
    "# Modeli derliyoruz. Optimizasyon fonksiyonunu, kayıp fonksiyonunu ve metrikleri belirtiyoruz.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Epoch ve batch size tanımla\n",
    "epc = 5 \n",
    "bs = 50\n",
    "\n",
    "# Modeli çalıştır\n",
    "# Modeli eğitiyoruz. Verileri kullanarak ağırlıkları güncelleyerek öğrenme sağlanıyor.\n",
    "history = model.fit(x_train, y_train, batch_size=bs, epochs=epc, validation_data=(x_validate, y_validate), verbose=1, callbacks=[learning_rate_reduction])\n",
    "\n",
    "# Doğruluk grafiklerini çiz\n",
    "# Eğitim sürecinin başarımını görselleştirmek için grafik çiziyoruz.\n",
    "plt.plot(history.history['accuracy'])\n",
    "# Eğitim sürecinin başarımını görselleştirmek için grafik çiziyoruz.\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Hata grafiklerini çiz\n",
    "# Eğitim sürecinin başarımını görselleştirmek için grafik çiziyoruz.\n",
    "plt.plot(history.history['loss'])\n",
    "# Eğitim sürecinin başarımını görselleştirmek için grafik çiziyoruz.\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "Y_pred = model.predict(x_validate)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "Y_true = np.argmax(y_validate, axis=1)\n",
    "\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Sınıf isimlerini almak için\n",
    "class_names = labelEn.inverse_transform(range(len(classes)))\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "plot_confusion_matrix(confusion_mtx, classes=class_names)\n",
    "\n",
    "# Modeli kaydetme\n",
    "# Çalışma dizinini değiştiriyoruz, böylece veri setine erişim kolay olur.\n",
    "os.chdir(r\"C:\\Users\\İbrahim Demir\\Desktop\\Yeni klasör\\models\")\n",
    "# Eğitilmiş modeli kaydediyoruz, böylece tekrar eğitmeye gerek kalmadan kullanabiliriz.\n",
    "model.save('model1.h5')\n",
    "\n",
    "# Veri Arttırımı (Data Augmentasyonu)\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Veri arttırımı ile birlikte modeli fit et\n",
    "# Modeli eğitiyoruz. Verileri kullanarak ağırlıkları güncelleyerek öğrenme sağlanıyor.\n",
    "history = model.fit(datagen.flow(np.array(x_train), np.array(y_train), batch_size=bs), \n",
    "                    epochs=epc, \n",
    "                    validation_data=datagen.flow(np.array(x_validate), np.array(y_validate), batch_size=bs), \n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=x_train.shape[0] // bs, \n",
    "                    callbacks=[learning_rate_reduction])\n",
    "\n",
    "# Sonuçların yazdırılması\n",
    "Y_pred = model.predict(x_test)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Sınıflandırma raporunu yazdırma\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(Y_true, Y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Karmaşıklık matrisini yazdırma\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "confusion_mtx_test = confusion_matrix(Y_true, Y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Modelin tahmin doğruluğunu değerlendirmek için karmaşıklık matrisini hesaplıyoruz.\n",
    "plot_confusion_matrix(confusion_mtx_test, classes=class_names)\n",
    "plt.title('Test Seti Karmaşıklık Matrisi')\n",
    "plt.show()\n",
    "\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "print(f\"Eğitim Doğruluğu: {train_acc:.4f}\")\n",
    "print(f\"Doğrulama Doğruluğu: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
